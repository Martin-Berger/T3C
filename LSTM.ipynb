{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A Keras tensor is a tensor object from the underlying backend (Theano or TensorFlow), \n",
    "#which we augment with certain attributes that allow us to build a Keras model just by knowing the inputs and \n",
    "#outputs of the model.\n",
    "#We use tensorflow backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, re, csv, codecs, numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('C:\\\\Users\\\\smrid\\\\Desktop\\\\train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since our test dataset is unlabelled, we split our data into 80-20 split of train and test(from train)\n",
    "train, test = train_test_split(data, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>121655</th>\n",
       "      <td>8aeb1743b941d9c2</td>\n",
       "      <td>Microwave Oven \\n\\nPlease do not add nonsense ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146545</th>\n",
       "      <td>2decf29db0bf99d2</td>\n",
       "      <td>\"\\n\\nThat edit? Fair play to whoever reverted ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116750</th>\n",
       "      <td>70213f013d7b16ad</td>\n",
       "      <td>\" Hi, OzWhiz, Welcome to Wikipedia! \\nI hope y...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95115</th>\n",
       "      <td>fe46a605802e1a63</td>\n",
       "      <td>Removing Warnings\\nPlease do not remove messag...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39598</th>\n",
       "      <td>69b361f25e9fbb30</td>\n",
       "      <td>Fair enough. The standards have change through...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text  \\\n",
       "121655  8aeb1743b941d9c2  Microwave Oven \\n\\nPlease do not add nonsense ...   \n",
       "146545  2decf29db0bf99d2  \"\\n\\nThat edit? Fair play to whoever reverted ...   \n",
       "116750  70213f013d7b16ad  \" Hi, OzWhiz, Welcome to Wikipedia! \\nI hope y...   \n",
       "95115   fe46a605802e1a63  Removing Warnings\\nPlease do not remove messag...   \n",
       "39598   69b361f25e9fbb30  Fair enough. The standards have change through...   \n",
       "\n",
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "121655      0             0        0       0       0              0  \n",
       "146545      0             0        0       0       0              0  \n",
       "116750      0             0        0       0       0              0  \n",
       "95115       0             0        0       0       0              0  \n",
       "39598       0             0        0       0       0              0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145244</th>\n",
       "      <td>1962767e67babbbe</td>\n",
       "      <td>I feel both qualify.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145033</th>\n",
       "      <td>165afdff82886453</td>\n",
       "      <td>Once upon a time, in a steppe far, far away......</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143475</th>\n",
       "      <td>ff3b03f1d3699f19</td>\n",
       "      <td>Yet more examples of ideologically motivated f...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19647</th>\n",
       "      <td>33e75061d0e63e9a</td>\n",
       "      <td>\"\\nThis logic is convoluted and general nonsen...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76960</th>\n",
       "      <td>ce18d4ed57970f36</td>\n",
       "      <td>And incidentally I know that much of what Cla6...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text  \\\n",
       "145244  1962767e67babbbe                               I feel both qualify.   \n",
       "145033  165afdff82886453  Once upon a time, in a steppe far, far away......   \n",
       "143475  ff3b03f1d3699f19  Yet more examples of ideologically motivated f...   \n",
       "19647   33e75061d0e63e9a  \"\\nThis logic is convoluted and general nonsen...   \n",
       "76960   ce18d4ed57970f36  And incidentally I know that much of what Cla6...   \n",
       "\n",
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "145244      0             0        0       0       0              0  \n",
       "145033      0             0        0       0       0              0  \n",
       "143475      0             0        0       0       0              0  \n",
       "19647       0             0        0       0       0              0  \n",
       "76960       0             0        0       0       0              0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(id               False\n",
       " comment_text     False\n",
       " toxic            False\n",
       " severe_toxic     False\n",
       " obscene          False\n",
       " threat           False\n",
       " insult           False\n",
       " identity_hate    False\n",
       " dtype: bool, id               False\n",
       " comment_text     False\n",
       " toxic            False\n",
       " severe_toxic     False\n",
       " obscene          False\n",
       " threat           False\n",
       " insult           False\n",
       " identity_hate    False\n",
       " dtype: bool)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for presence of any null values, toxic dataset does not have any null values\n",
    "train.isnull().any(),test.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text data must be encoded as numbers to be used as input or output for deep learning models.\n",
    "#keras provides tokenization where we break down our comments into unique words and put the words in a list and index each word.\n",
    "#This chain of indexes will be fed to the LSTM\n",
    "#So this is what we are going to do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train[list_classes].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_sentences_train = train[\"comment_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_sentences_test = test[\"comment_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 20000\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(list_sentences_train))\n",
    "list_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\n",
    "list_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[18397,\n",
       "  15768,\n",
       "  45,\n",
       "  33,\n",
       "  14,\n",
       "  149,\n",
       "  833,\n",
       "  2,\n",
       "  28,\n",
       "  11,\n",
       "  8,\n",
       "  406,\n",
       "  194,\n",
       "  22,\n",
       "  6,\n",
       "  47,\n",
       "  49,\n",
       "  2,\n",
       "  1241,\n",
       "  81,\n",
       "  1,\n",
       "  578,\n",
       "  127,\n",
       "  6]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_tokenized_train[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM requires the data to be of fixed length, that is same number of features, but the comments can be of various lengths\n",
    "#and hence the indexing length might vary\n",
    "#Hence we go for padding where we set a maxlen allowed to some number(200 in our case) and pad the shorter ones with zeros and \n",
    "#cut short the longer ones --> done using pad function\n",
    "#We saw the distribution of number of words in sentences in the entire dataset and came up with a convinient number 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 200\n",
    "X_t = pad_sequences(list_tokenized_train, maxlen=maxlen)\n",
    "X_te = pad_sequences(list_tokenized_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalNumWords = [len(one_comment) for one_comment in list_tokenized_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Below plot to obtain the optimum maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(totalNumWords,bins = np.arange(0,410,10))#[0,50,100,150,200,250,300,350,400])#,450,500,550,600,650,700,750,800,850,900])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First of all, input function is used to create and define a standalone Input layer that specifies the shape of input data.\n",
    "#The input layer takes a shape argument that is a tuple that indicates the dimensionality of the input data.\n",
    "\n",
    "#When input data is one-dimensional, the shape must explicitly leave room for the shape of the \n",
    "#mini-batch size used when splitting the data when training the network. \n",
    "#Therefore, the shape tuple is always defined with a hanging last dimension when the input is one-dimensional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'input_2:0' shape=(?, 200) dtype=float32>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = Input(shape=(maxlen, ))\n",
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output from the Input() is passed on to the embedding layer where the words are defined in a vector space depending on the\n",
    "#surrounding words, the output of the embedding layer is a list of co-ordinates of the words in the vector space.\n",
    "#Basically it's a mapping of the original input data into some set of real-valued dimensions, \n",
    "#and the \"position\" of the original input data in those dimensions is organized to improve the task.\n",
    "#So, similar words might be put on the same dimensiona nd hence the overall dimensions are reduced drastically. Distance between words\n",
    "#are used to determine the relevance of concepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 128\n",
    "x = Embedding(max_features, embed_size)(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In LSTM, we feed the output of one layer as an input to the next layer. Final output is taken after some number of recursions.\n",
    "#We want out LSTM to produce output with dimensions as 60.\n",
    "#Taking input from the previous layers, LSTM runs 200 times, passing the coordinates of the words each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = LSTM(60, return_sequences=True,name='lstm_layer')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the model x obtained after fillting LSTM will be a 3D model, we need to convert the same into a 2D one, hence we use GlobalMaxPool()\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = GlobalMaxPool1D()(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In order to get e generalization of the data, we remove some part of the data so that the next layer handles missing data forcefully\n",
    "# Dropout(0.1) disables 10% of the nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Dropout(0.1)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The output of Dropout is given as input to a \"Relu\" activation function----->why RELU??\n",
    "#Dimension of the output is set to 50\n",
    "#Again a Dropout of 10% is achieved and the output is now given to a sigmoid function.\n",
    "#Sigmoid function produces output between 0 and 1, hence we achive a binary classification for each of the 6 labels;."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Dense(50, activation=\"relu\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Dropout(0.1)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Dense(6, activation=\"sigmoid\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Did not understand the parameters properly, why have we used adam and what is binary_crossentropy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=inp, outputs=x)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #We'll feed in a list of 32 padded, indexed sentence for each batch and split 10% of the data as a validation set.\n",
    "#This validation set will be used to assess whether the model has overfitted, for each batch. \n",
    "#The model will also run for 2 epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we catually should consider the total training size/batch size, that many number of batches pass through our algorithm \n",
    "#in each epoch.\n",
    "#Typically, you'll split your test set into small batches for the network to learn from,\n",
    "#and make the training go step by step through your number of layers, applying gradient-descent all the way down.\n",
    "#All these small steps can be called iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 114890 samples, validate on 12766 samples\n",
      "Epoch 1/2\n",
      "114890/114890 [==============================] - 1130s 10ms/step - loss: 0.0769 - acc: 0.9752 - val_loss: 0.0460 - val_acc: 0.9830\n",
      "Epoch 2/2\n",
      "114890/114890 [==============================] - 1030s 9ms/step - loss: 0.0459 - acc: 0.9828 - val_loss: 0.0449 - val_acc: 0.9835\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21a18130390>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 2\n",
    "model.fit(X_t,y, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
